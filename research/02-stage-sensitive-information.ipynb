{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb65d2d",
   "metadata": {},
   "source": [
    "# Privacy and Compliance Violation\n",
    "- Identify all the call ids where agents have shared sensitive information (balance\n",
    "or account details) without the identity verification(i.e. without verification of date\n",
    "of birth or address or Social Security Number).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52569133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:00, 2717.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00be25b0-458f-4cbf-ae86-ae2ec1f7fba4: {'violation': False, 'violation_types': []}\n",
      "019b9e97-9575-459e-9893-b59d8c99acef: {'violation': False, 'violation_types': []}\n",
      "02b08433-58e0-46af-961e-221ba94cb8df: {'violation': False, 'violation_types': []}\n",
      "02f1cff9-7d47-4168-b1f9-d9fba10847a0: {'violation': True, 'violation_types': ['Amount']}\n",
      "03132d8f-6a7d-47d0-9540-c6a0ac32d946: {'violation': True, 'violation_types': ['Amount', 'phone']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_sensitive_patterns():\n",
    "    return {\n",
    "        \"ssn\": re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"),\n",
    "        \"phone\": re.compile(r\"\\b(?:\\+91[-\\s]?|0)?\\d{10}\\b\"),\n",
    "        \"email\": re.compile(r\"\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-z]{2,}\\b\"),\n",
    "        \"credit_card\": re.compile(r\"\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b\"),\n",
    "        \"address\": re.compile(r\"\\b\\d{1,5}\\s\\w+\\s(?:Street|St|Avenue|Ave|Road|Rd|Lane|Ln)\\b\", re.I),\n",
    "        \"pan\": re.compile(r\"\\b[A-Z]{5}\\d{4}[A-Z]\\b\"),\n",
    "        \"aadhaar\": re.compile(r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"),\n",
    "        \"phone\": re.compile(r\"\\b\\d{3}-\\d{3}-\\d{4}\\b\"),\n",
    "        \"address\": re.compile(r'\\d+\\s\\w+\\s\\w+,\\s\\w+'),\n",
    "        \"passport\": re.compile(r\"\\b[A-Z]{1}[0-9]{7}\\b\"),\n",
    "        \"bank_account\": re.compile(r\"\\b\\d{9,18}\\b\"),\n",
    "        \"dob\": re.compile(r\"\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b\"),\n",
    "        \"email_address\": re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}')\n",
    "    }\n",
    "\n",
    "def get_verification_keywords():\n",
    "    return [\"date of birth\", \"dob\", \"address\", \"ssn\", \"social security number\", \"verification\"]\n",
    "\n",
    "def contains_verification(text):\n",
    "    text = text.lower()\n",
    "    return any(key in text for key in get_verification_keywords())\n",
    "\n",
    "def contains_sensitive(text, patterns):\n",
    "    found = []\n",
    "    for name, pattern in patterns.items():\n",
    "        if pattern.search(text):\n",
    "            found.append(name)\n",
    "    return found\n",
    "\n",
    "def check_privacy_violation(convo_json):\n",
    "    patterns = get_sensitive_patterns()\n",
    "    verified = False\n",
    "    violations = []\n",
    "\n",
    "    for line in convo_json:\n",
    "        speaker = line[\"speaker\"]\n",
    "        text = line[\"text\"]\n",
    "\n",
    "        if speaker.lower() == \"agent\":\n",
    "            if contains_verification(text):\n",
    "                verified = True\n",
    "\n",
    "            if not verified:\n",
    "                sensitive_found = contains_sensitive(text, patterns)\n",
    "                if sensitive_found:\n",
    "                    violations.extend(sensitive_found)\n",
    "        verified = False  # Reset for the next line\n",
    "\n",
    "    return list(set(violations))  # Unique violation types\n",
    "\n",
    "def process_conversations(folder_path):\n",
    "    results = {}\n",
    "\n",
    "    for file in tqdm(Path(folder_path).glob(\"*.json\")):\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                convo = json.load(f)\n",
    "\n",
    "            violations = check_privacy_violation(convo)\n",
    "            results[file.stem] = {\n",
    "                \"violation\": bool(violations),\n",
    "                \"violation_types\": violations\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in file {file.name}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use your actual path here\n",
    "    CONVO_FOLDER = \"C:/Users/Rounak/Desktop/OneDrive/College/Projects/prodigal-solutions-engineer/artifacts/All_Conversations\"\n",
    "    \n",
    "    result = process_conversations(CONVO_FOLDER)\n",
    "\n",
    "    # Sample print\n",
    "    for call_id, info in list(result.items())[:5]:\n",
    "        print(f\"{call_id}: {info}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125a9cb",
   "metadata": {},
   "source": [
    "# LLM - GROQ Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4d35b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from groq import Groq\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_KEY = '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'\n",
    "\n",
    "def get_groq_client():\n",
    "    return Groq(api_key=API_KEY)\n",
    "\n",
    "def load_config(path=\"config.yaml\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "# Format conversation\n",
    "def format_conversation(json_data):\n",
    "    return \"\\n\".join([f\"{x['speaker']}: {x['text']}\" for x in json_data])\n",
    "\n",
    "\n",
    "def check_sensitive_information(convo_text, client, model=\"llama3-70b-8192\"):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    I am giving you a conversation between a customer and an agent in JSON format.\n",
    "    Check strictly if agent have shared balance in any currency or account details of customer without the identity verification of customer (i.e. without verification of date of birth, address, or Social Security Number).\n",
    "    Strictly give output in this Python list format: \n",
    "\n",
    "    [True if shared else False] \n",
    "\n",
    "    NOTE: I do not want python code. I do not want any explaination.\n",
    "\n",
    "    Here is the conversation between the customer and agent in JSON format:\n",
    "    {convo_text}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # API call to the model\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=model,\n",
    "        )\n",
    "        \n",
    "        # Get the response content\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        #convert into python list\n",
    "        reply = eval(reply)\n",
    "\n",
    "\n",
    "        return reply\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Main processing function\n",
    "def process_all_to_dict(folder_path, client):\n",
    "    results = {}\n",
    "\n",
    "    for file in tqdm(Path(folder_path).glob(\"*.json\")):\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                convo_json = json.load(f)\n",
    "\n",
    "            # convo_text = format_conversation(convo_json)\n",
    "            result = check_sensitive_information(convo_json, client)\n",
    "            results[file.stem] = result[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {file.name}: {e}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "68b5eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [25:06,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Profanity dictionary created. Sample:\n",
      "\n",
      "00be25b0-458f-4cbf-ae86-ae2ec1f7fba4 : False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = load_config()\n",
    "    folder_path = config[\"ProfaneWords\"][\"CONVERSATIONS_FOLDER\"]\n",
    "    client = get_groq_client()\n",
    "\n",
    "    profane_data = process_all_to_dict(folder_path, client)\n",
    "    \n",
    "    # You can now use this dictionary however you want\n",
    "    print(\"✅ Profanity dictionary created. Sample:\\n\")\n",
    "    sample_key = next(iter(profane_data))\n",
    "    print(sample_key, \":\", profane_data[sample_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabeafed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b94fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
